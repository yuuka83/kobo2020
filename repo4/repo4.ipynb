{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題４\n",
    "１８１００８３　井上悠香"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss関数の一つであるSoftmax with lossレイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#交差エントロピー誤差\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "   # 教師データがone-hot-vectorの場合、正解ラベルのインデックスに変換\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "        batch_size = y.shape[0]\n",
    "        return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#ソフトマックス関数\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Softmaxに入れてその後、交差エントロピー誤差を求めて損失を求めるレイヤ　\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None # softmaxの出力\n",
    "        self.t = None # 教師データ\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t                  #教師データ\n",
    "        self.y = softmax(x)#xを代入して確率を出す。\n",
    "        #損失関数\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self,dout = 1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t)/batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two layer netにおける勾配の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reluレイヤ\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx\n",
    "    \n",
    "#Affineレイヤ\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "       # 重み・バイアスパラメータの微分\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    def forward(self, x):\n",
    "       # テンソル対応\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "        return out\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        dx = dx.reshape(*self.original_x_shape)  # 入力データの形状に戻す（テンソル対応）\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#誤差逆伝播法\n",
    "#重みパラメータに対する勾配を誤差逆伝播法によって求める\n",
    "def gradient(network, x, t):\n",
    "    # 自分で実装したSoftmax with lossクラスを使ってみてください\n",
    "    lastLayer = network.lastLayer      #networkのSoftmaxwithLossレイヤーを使うのでnetwork.lastlayerを入れる\n",
    "    self = network                                #ここでのselfはnetwork\n",
    "    # forward\n",
    "    #self.loss(x, t)\n",
    "    network.loss(x, t)\n",
    "    # backward\n",
    "    dout = 1\n",
    "    dout = lastLayer.backward(dout)\n",
    "    #layers = list(self.layers.values())\n",
    "    layers = list(network.layers.values())\n",
    "    layers.reverse()\n",
    "    for layer in layers:\n",
    "        dout = layer.backward(dout)\n",
    "    # 設定\n",
    "    grads = {}\n",
    "    #grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "    grads['W1'], grads['b1'] = network.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "    #grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "    grads['W2'], grads['b2'] = network.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "from common.functions import *\n",
    "\n",
    "def numerical_grad(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val # 値を元に戻す\n",
    "        it.iternext()   \n",
    "    return grad\n",
    "\n",
    "\n",
    "#勾配を返すTwoLayerNet\n",
    "class TwoLayerNet:\n",
    "    #\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "       # 重みの初期化　重みのリストparams\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "       # レイヤの生成  辞書型\n",
    "        self.layers = OrderedDict()\n",
    "        #layers['Affine1']は、Affineレイヤに'W1'の重みと'b1'を与えたもの\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        #layers['Relu']は、Reluレイヤ\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        #layers['Affine2']は、Affineレイヤに'W2'の重みと'b2'を与えたもの\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        #上のlayersリストとは別にlastLayerにSoftmaxWithLossレイヤを保存\n",
    "        self.lastLayer = SoftmaxWithLoss() \n",
    "        \n",
    "    def predict(self, x):\n",
    "        #layersに入っているレイヤーを順番に　　Affine1→Relu→Affine2　出力が次の層の入力\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)                   #各layerのforward処理していく\n",
    "        return x\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        #np.argmax(最大値を取得したい配列,軸方向)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "          \n",
    "   # x:入力データ, t:教師データ\n",
    "    #損失関数\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    #数値微分\n",
    "    def numerical_gradient(self, x, t):\n",
    "        #損失関数で求めた値をloss_Wに入れる\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        grads = {}\n",
    "        #重みパラメータに対する勾配を数値微分によって求める\n",
    "        grads['W1'] = numerical_grad(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_grad(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_grad(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_grad(loss_W, self.params['b2'])\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:2.818318783926189e-13\n",
      "b1:1.1542968837707778e-12\n",
      "W2:1.0057510494733673e-12\n",
      "b2:1.2057022880096468e-10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#データを読み込んで実行する\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "#network 　に TwoLayerNetをインスタンス化して処理\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "# 数値微分　ネットワーク\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "# Backward\n",
    "grad_backprop = gradient(network, x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )#順伝播の勾配と逆伝播の勾配の差\n",
    "    print(key + \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大きくて$1.1205e^{-10}$という十分小さな値が出力された。出力は、順伝播の勾配と逆伝播の勾配の差であるから、順伝播と逆伝播の勾配にはほとんど違いがないことが確認できた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回のエラー<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<ipython-input-73-ef36eae4638b> in backward(self, dout)\n",
    "     14         return self.loss\n",
    "     15     def backward(self,dout = 1):\n",
    "---> 16         batch_size = self.t.shape[0]\n",
    "     17         dx = (self.y - self.t)/batch_size\n",
    "     18         return dx\n",
    "\n",
    "AttributeError: 'NoneType' object has no attribute 'shape' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NoneTypeオブジェクトとは、Noneタイプのオブジェクトであり、値なしを示すオブジェクトのこと。おそらくCでいうNullのようなもの？<br>\n",
    "ここでは、softmaxWithLayer の　self.tがNoneTypeと言われている。softmaxWithLayerのtへの代入は、順伝播(forward)で行われている。逆伝播は順伝播がないとできない。softmaxWithLayerは、TwoNetLayerでは、他のレイヤとは、一つだけ別にlastLayerというレイヤに代入されている。（他のレイヤはlayersリストに入っている。）gradientを実行するときにgradientのlastLayerにnetwork.lastLayerを代入しなきゃいけなかった。\n",
    "参考：[「nonetype」オブジェクトとは何ですか？](https://www.it-swarm.dev/ja/python/%E3%80%8Cnonetype%E3%80%8D%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%81%A8%E3%81%AF%E4%BD%95%E3%81%A7%E3%81%99%E3%81%8B%EF%BC%9F/1044227590/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two layer netの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11916666666666667 0.1168\n",
      "0.90175 0.9027\n",
      "0.9225333333333333 0.9239\n",
      "0.9359666666666666 0.9356\n",
      "0.9438 0.9433\n",
      "0.949 0.9462\n",
      "0.9553 0.9523\n",
      "0.96045 0.9575\n",
      "0.9635666666666667 0.9611\n",
      "0.96715 0.9626\n",
      "0.96845 0.9643\n",
      "0.9712666666666666 0.9649\n",
      "0.9737333333333333 0.9678\n",
      "0.9745333333333334 0.9681\n",
      "0.9759666666666666 0.9691\n",
      "0.9772666666666666 0.9701\n",
      "0.9782166666666666 0.9703\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "for i in range(iters_num):\n",
    "        batch_mask = np.random.choice(train_size, batch_size)\n",
    "        x_batch = x_train[batch_mask]\n",
    "        t_batch = t_train[batch_mask]\n",
    "       # 勾配\n",
    "        #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "       #grad = gradient(x_batch, t_batch)\n",
    "        grad = gradient(network, x_batch, t_batch)\n",
    "       # 更新\n",
    "        for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "            network.params[key] -= learning_rate * grad[key]\n",
    "        loss = network.loss(x_batch, t_batch)\n",
    "        train_loss_list.append(loss)\n",
    "        if i % iter_per_epoch == 0:\n",
    "            train_acc = network.accuracy(x_train, t_train)\n",
    "            test_acc = network.accuracy(x_test, t_test)\n",
    "            train_acc_list.append(train_acc)\n",
    "            test_acc_list.append(test_acc)\n",
    "            print(train_acc, test_acc)\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回と同じようにグラフを出力してみた。今回は、誤差逆伝播（gradient）を使用して学習したが、認識精度のグラフは前回と似たような形になった。これは、前の問題で、順伝播の勾配と誤差逆伝播の勾配にほぼ差が無かったことから導かれる結果である。<br>\n",
    "今回も認識精度は高く、最終的に97パーセントになっている。\n",
    "参考：[【学習メモ】ゼロから作るDeep Learning【5章】](https://qiita.com/yakof11/items/5d37042f689760515072)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
